# ğŸ”¬ Scientific Research Plan: Neuroscience Foundation Models

## Executive Summary

ë³¸ ë¬¸ì„œëŠ” SNU Connectome Fellows Programì˜ í•µì‹¬ ì—°êµ¬ ë°©í–¥ì¸ **Neuroscience Foundation Models** ê°œë°œì„ ìœ„í•œ ê³¼í•™ì  ì—°êµ¬ ê³„íšì„ ì œì‹œí•©ë‹ˆë‹¤.

---

## 1. ì—°êµ¬ ë°°ê²½ ë° ë™ê¸°

### 1.1 Foundation Modelsì˜ ë¶€ìƒ

2024-2025ë…„, ì‹ ê²½ê³¼í•™ ë¶„ì•¼ì—ì„œ Foundation Model íŒ¨ëŸ¬ë‹¤ì„ì´ ê¸‰ë¶€ìƒí–ˆìŠµë‹ˆë‹¤:

```
Traditional Approach          Foundation Model Approach
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Task-specific models        â€¢ Pre-trained on massive data
â€¢ Small datasets              â€¢ Zero-shot/few-shot transfer
â€¢ Limited generalization      â€¢ Universal representations
â€¢ Siloed experiments          â€¢ Cross-dataset learning
```

### 1.2 ì£¼ìš” ì„ í–‰ ì—°êµ¬

| ëª¨ë¸ | ì—°ë„ | í•µì‹¬ ê¸°ì—¬ | ë°ì´í„° |
|------|------|----------|--------|
| **BrainLM** | 2024 | Autoregressive fMRI modeling | 6,700 hours |
| **Brain-JEPA** | 2024 | Joint-Embedding + Gradient Positioning | UK Biobank |
| **Brain Harmony** | 2025 | Morphology-Function í†µí•© | Multi-modal |
| **fMRI-LM** | 2025 | Language grounding | HCP + Narratives |

### 1.3 ì—°êµ¬ ê²©ì°¨ (Research Gap)

í˜„ì¬ ì—°êµ¬ë“¤ì˜ í•œê³„:
1. **ë‹¨ì¼ ëª¨ë‹¬ë¦¬í‹°**: fMRI ë˜ëŠ” EEGë§Œ ë‹¨ë… ì‚¬ìš©
2. **ê³µí•™ ì¤‘ì‹¬**: ê³¼í•™ì  í•´ì„ ë¶€ì¡±
3. **ìƒì„± ëª¨ë¸ ë¶€ì¬**: ì˜ˆì¸¡ë§Œ ê°€ëŠ¥, ìƒì„± ë¶ˆê°€
4. **í‘œìƒ í•™ìŠµ ì œí•œ**: ë‡Œì˜ ê³µí†µ í‘œìƒ ë¯¸ë°œê²¬

---

## 2. ì—°êµ¬ ëª©í‘œ

### 2.1 í•µì‹¬ ì—°êµ¬ ì§ˆë¬¸

> **RQ1**: ë‹¤ì–‘í•œ ì‹ ê²½ ë°ì´í„° ëª¨ë‹¬ë¦¬í‹°(fMRI, EEG, MEG, ë‹¨ì¼ ë‰´ëŸ°)ë¡œë¶€í„°
> ê³µí†µëœ ë‡Œ í‘œìƒ(unified brain representation)ì„ í•™ìŠµí•  ìˆ˜ ìˆëŠ”ê°€?

> **RQ2**: Foundation Modelê³¼ ìƒì„± ëª¨ë¸(Diffusion, VAE)ì„ ê²°í•©í•˜ì—¬
> ë‡Œ í™œë™ì„ ì˜ˆì¸¡í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆëŠ”ê°€?

> **RQ3**: ì´ëŸ¬í•œ ëª¨ë¸ì´ ì¸ê°„ ë‡Œì˜ ê³„ì‚° ì›ë¦¬ë¥¼ ë°íˆëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆëŠ”ê°€?

### 2.2 ì—°êµ¬ ëª©í‘œ ì²´ê³„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Research Objective Hierarchy                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Ultimate Goal: ë‡Œì˜ ê³„ì‚° ì›ë¦¬ ì´í•´                          â”‚
â”‚        â”‚                                                     â”‚
â”‚        â”œâ”€â–º Long-term (5ë…„): Unified Brain Foundation Model  â”‚
â”‚        â”‚     â€¢ Multi-species, multi-scale                   â”‚
â”‚        â”‚     â€¢ Interpretable representations                â”‚
â”‚        â”‚                                                     â”‚
â”‚        â”œâ”€â–º Mid-term (2-3ë…„): Multimodal + Generative FM    â”‚
â”‚        â”‚     â€¢ fMRI + EEG + Language integration           â”‚
â”‚        â”‚     â€¢ Brain activity generation                    â”‚
â”‚        â”‚                                                     â”‚
â”‚        â””â”€â–º Short-term (1ë…„): Single-modality FM ì¬í˜„/ê°œì„   â”‚
â”‚              â€¢ BrainLM, Brain-JEPA ì¬í˜„                     â”‚
â”‚              â€¢ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ì ìš©                          â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. ë°©ë²•ë¡ 

### 3.1 Phase 1: Foundation Model ì¬í˜„ ë° ì´í•´ (Year 1)

#### 3.1.1 BrainLM ì¬í˜„

```python
# BrainLM Architecture Reproduction
class BrainLM(nn.Module):
    """
    Autoregressive Foundation Model for fMRI
    
    Architecture:
    - Transformer encoder-decoder
    - Temporal attention across TRs
    - ROI-level tokenization
    """
    
    def __init__(self, 
                 num_rois: int = 400,      # Schaefer parcellation
                 d_model: int = 768,
                 n_heads: int = 12,
                 n_layers: int = 12,
                 max_seq_len: int = 512):
        super().__init__()
        
        # ROI embedding
        self.roi_embed = nn.Linear(num_rois, d_model)
        
        # Positional encoding (temporal)
        self.pos_encoding = SinusoidalPositionalEncoding(d_model, max_seq_len)
        
        # Transformer layers
        self.transformer = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(d_model, n_heads, dim_feedforward=3072),
            num_layers=n_layers
        )
        
        # Prediction head
        self.predict_head = nn.Linear(d_model, num_rois)
        
    def forward(self, x, mask=None):
        """
        x: (batch, time, num_rois) - fMRI time series
        returns: (batch, time, num_rois) - predicted next states
        """
        x = self.roi_embed(x)
        x = x + self.pos_encoding(x)
        x = self.transformer(x, mask=mask)
        return self.predict_head(x)
```

#### 3.1.2 Brain-JEPA ì¬í˜„

```python
# Brain-JEPA: Joint-Embedding Predictive Architecture
class BrainJEPA(nn.Module):
    """
    JEPA for brain dynamics
    
    Key innovations:
    - Gradient positioning encoding
    - Spatiotemporal masking
    - Latent space prediction (not pixel-level)
    """
    
    def __init__(self):
        super().__init__()
        
        # Context encoder (online)
        self.context_encoder = TransformerEncoder(...)
        
        # Target encoder (EMA updated)
        self.target_encoder = TransformerEncoder(...)
        
        # Predictor network
        self.predictor = TransformerDecoder(...)
        
        # Gradient positioning
        self.gradient_pos = GradientPositionalEncoding()
        
    def forward(self, x, mask_context, mask_target):
        """
        x: brain data (batch, time, space)
        
        Training objective:
        - Mask parts of the data
        - Predict masked regions in LATENT space
        - EMA update target encoder
        """
        # Context: unmasked regions
        context = self.context_encoder(x * mask_context)
        
        # Target: masked regions (stop gradient)
        with torch.no_grad():
            target = self.target_encoder(x * mask_target)
        
        # Predict targets from context
        predictions = self.predictor(context, target_positions)
        
        return F.mse_loss(predictions, target.detach())
```

### 3.2 Phase 2: Multimodal Integration (Year 2)

#### 3.2.1 Cross-Modal Alignment

```python
class MultimodalBrainFM(nn.Module):
    """
    Multimodal Brain Foundation Model
    
    Modalities:
    - fMRI: BOLD signal, low temporal resolution
    - EEG: Electrical activity, high temporal resolution
    - MEG: Magnetic fields, source-localized
    - Language: Stimulus transcripts
    """
    
    def __init__(self):
        super().__init__()
        
        # Modality-specific encoders
        self.fmri_encoder = BrainLM(...)
        self.eeg_encoder = EEGNet(...)
        self.meg_encoder = MEGTransformer(...)
        self.language_encoder = WhisperEncoder(...)  # or LLM
        
        # Shared latent space projectors
        self.fmri_proj = nn.Linear(768, 512)
        self.eeg_proj = nn.Linear(256, 512)
        self.meg_proj = nn.Linear(512, 512)
        self.lang_proj = nn.Linear(1024, 512)
        
        # Cross-modal attention
        self.cross_attention = CrossModalAttention(512, 8)
        
    def align_representations(self, fmri, eeg, language):
        """
        Align representations across modalities using:
        1. Contrastive learning (CLIP-like)
        2. Cross-modal attention
        3. Joint embedding space
        """
        # Encode each modality
        z_fmri = self.fmri_proj(self.fmri_encoder(fmri))
        z_eeg = self.eeg_proj(self.eeg_encoder(eeg))
        z_lang = self.lang_proj(self.language_encoder(language))
        
        # Cross-modal alignment loss
        loss_fmri_eeg = contrastive_loss(z_fmri, z_eeg)
        loss_fmri_lang = contrastive_loss(z_fmri, z_lang)
        
        return loss_fmri_eeg + loss_fmri_lang
```

### 3.3 Phase 3: Generative Brain Model (Year 2-3)

#### 3.3.1 Diffusion-based Brain Generation

```python
class BrainDiffusion(nn.Module):
    """
    Latent Diffusion Model for Brain Activity Generation
    
    Capabilities:
    1. Unconditional brain activity generation
    2. Stimulus-conditioned generation (image â†’ brain)
    3. Language-conditioned generation (text â†’ brain)
    4. Brain-to-brain translation
    """
    
    def __init__(self):
        super().__init__()
        
        # Variational encoder (compress to latent)
        self.encoder = BrainVAE(...)
        
        # Diffusion model in latent space
        self.unet = UNet3D(
            in_channels=64,   # Latent channels
            out_channels=64,
            time_embed_dim=256,
            condition_dim=512  # For conditioning
        )
        
        # Decoder (latent â†’ brain)
        self.decoder = BrainDecoder(...)
        
    def forward(self, brain_data, condition=None, timestep=None):
        """
        Training: Learn to denoise
        Inference: Generate brain activity from noise
        """
        # Encode to latent
        z = self.encoder(brain_data)
        
        # Add noise
        noise = torch.randn_like(z)
        noisy_z = self.add_noise(z, noise, timestep)
        
        # Predict noise (conditioned)
        pred_noise = self.unet(noisy_z, timestep, condition)
        
        return F.mse_loss(pred_noise, noise)
    
    @torch.no_grad()
    def generate(self, condition=None, steps=50):
        """Generate brain activity from condition"""
        z = torch.randn(1, 64, T, H, W)
        
        for t in reversed(range(steps)):
            pred_noise = self.unet(z, t, condition)
            z = self.denoise_step(z, pred_noise, t)
        
        brain_activity = self.decoder(z)
        return brain_activity
```

---

## 4. ë°ì´í„°ì…‹

### 4.1 ì‚¬ìš© ë°ì´í„°ì…‹

| ë°ì´í„°ì…‹ | ëª¨ë‹¬ë¦¬í‹° | í¬ê¸° | ìš©ë„ |
|----------|----------|------|------|
| **UK Biobank** | fMRI | 50,000+ subjects | Pre-training |
| **HCP** | fMRI, MEG | 1,200 subjects | Multi-modal |
| **Narratives** | fMRI + Audio | 345 subjects | Language alignment |
| **THINGS-EEG** | EEG | 50 subjects | Vision-brain |
| **NSD** | fMRI | 8 subjects (dense) | Image reconstruction |

### 4.2 ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```python
class BrainDataPipeline:
    """Standard preprocessing for brain data"""
    
    def preprocess_fmri(self, bold_img):
        """
        1. Motion correction
        2. Spatial normalization (MNI)
        3. Temporal filtering (0.01-0.1 Hz)
        4. Parcellation (Schaefer 400)
        5. Z-score normalization
        """
        pass
    
    def preprocess_eeg(self, raw_eeg):
        """
        1. Bandpass filter (0.1-100 Hz)
        2. ICA artifact removal
        3. Re-referencing (average)
        4. Epoching
        5. Time-frequency decomposition
        """
        pass
```

---

## 5. í‰ê°€ ì§€í‘œ

### 5.1 Downstream Tasks

| Task | Metric | Baseline | Target |
|------|--------|----------|--------|
| **Brain State Prediction** | Accuracy | 75% | 90% |
| **Disease Classification** | AUC-ROC | 0.70 | 0.85 |
| **Age Prediction** | MAE | 5.0 years | 3.0 years |
| **Cognitive Score Prediction** | rÂ² | 0.30 | 0.50 |
| **Language Decoding** | BLEU | 0.10 | 0.30 |

### 5.2 Representation Quality

```python
def evaluate_representations(model, data):
    """
    Representation quality metrics
    """
    metrics = {
        # Linear probe accuracy
        'linear_probe': linear_probe_eval(model, data),
        
        # Brain-model alignment
        'brain_alignment': compute_rsa_correlation(model, data),
        
        # Cross-dataset transfer
        'transfer_acc': cross_dataset_eval(model, data),
        
        # Generalization to new subjects
        'subject_generalization': leave_one_out_eval(model, data),
    }
    return metrics
```

---

## 6. ì˜ˆìƒ ê¸°ì—¬

### 6.1 ê³¼í•™ì  ê¸°ì—¬

1. **Unified Brain Representation**
   - ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ë¥¼ í†µí•©í•˜ëŠ” ê³µí†µ ë‡Œ í‘œìƒ ë°œê²¬
   - ë‡Œì˜ ê³„ì‚° ì›ë¦¬ì— ëŒ€í•œ ìƒˆë¡œìš´ í†µì°°

2. **Generative Understanding**
   - ë‡Œ í™œë™ íŒ¨í„´ì˜ ìƒì„±ì  ì´í•´
   - Stimulus-response ê´€ê³„ì˜ ì¸ê³¼ì  ëª¨ë¸ë§

3. **Interpretability**
   - Foundation Modelì˜ ë‚´ë¶€ í‘œìƒ ë¶„ì„
   - ì‹ ê²½ê³¼í•™ì  í•´ì„ ê°€ëŠ¥ì„±

### 6.2 ê¸°ìˆ ì  ê¸°ì—¬

1. **Open-source Models**: BrainLM, Brain-JEPA í•œêµ­ì–´ ë¬¸ì„œí™” ë° ê°œì„ 
2. **Benchmark Suite**: ì‹ ê²½ê³¼í•™ FM í‰ê°€ ë²¤ì¹˜ë§ˆí¬ ê°œë°œ
3. **Pre-trained Checkpoints**: í•œêµ­ì¸ ë°ì´í„° ê¸°ë°˜ fine-tuning

---

## 7. íƒ€ì„ë¼ì¸

```
Year 1 (2025-2026)
â”œâ”€â”€ Q1: BrainLM ì¬í˜„ ë° ì´í•´
â”œâ”€â”€ Q2: Brain-JEPA ì¬í˜„ ë° í•œêµ­ ë°ì´í„° ì ìš©
â”œâ”€â”€ Q3: ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
â””â”€â”€ Q4: ì²« ë²ˆì§¸ ë…¼ë¬¸ íˆ¬ê³  (ì¬í˜„ + ê°œì„ )

Year 2 (2026-2027)
â”œâ”€â”€ Q1: Multimodal alignment ì—°êµ¬ ì‹œì‘
â”œâ”€â”€ Q2: Generative model ê°œë°œ
â”œâ”€â”€ Q3: ëŒ€ê·œëª¨ ì‹¤í—˜ ë° í‰ê°€
â””â”€â”€ Q4: ì£¼ìš” í•™íšŒ ë…¼ë¬¸ íˆ¬ê³  (NeurIPS/ICLR)

Year 3 (2027-2028)
â”œâ”€â”€ Q1: Unified Brain FM ê°œë°œ
â”œâ”€â”€ Q2: ê³¼í•™ì  í•´ì„ ì—°êµ¬
â”œâ”€â”€ Q3: ì„ìƒ ì‘ìš© íƒìƒ‰
â””â”€â”€ Q4: ìµœì¢… ë…¼ë¬¸ (Nature/Science ê³„ì—´)
```

---

## 8. í˜‘ë ¥ ì—°êµ¬

### 8.1 êµ­ì œ í˜‘ë ¥

- **Princeton (Hasson Lab)**: Language-brain alignment
- **BNL (ìœ ì‹ ì¬/ë°•ê¸°íƒœ)**: Brain imaging analysis
- **MIT (Poggio Lab)**: Computational theory
- **Stanford (Yamins Lab)**: Neural network-brain comparison

### 8.2 êµ­ë‚´ í˜‘ë ¥

- **KAIST ë‡Œì¸ì§€ê³µí•™ê³¼**: EEG/BCI ì—°êµ¬
- **ê³ ë ¤ëŒ€ ë‡Œê³µí•™ê³¼**: Brain-computer interface
- **ì‚¼ì„±ì„œìš¸ë³‘ì›**: ì„ìƒ ë°ì´í„°

---

## ì°¸ê³  ë¬¸í—Œ

1. Caro, J.O. et al. (2024). BrainLM: A foundation model for brain activity recordings. ICLR.
2. Dong, X. et al. (2024). Brain-JEPA: Brain Dynamics Foundation Model with Gradient Positioning. NeurIPS.
3. (2025). Brain Harmony: A Multimodal Foundation Model. NeurIPS.
4. (2025). Foundation model of neural activity predicts response to new stimulus types. Nature.
5. Hasson, U. et al. (2022). Shared computational principles for language processing. Nature Neuroscience.

---

*Document Version: 1.0*
*Last Updated: December 2025*




